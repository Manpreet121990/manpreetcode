{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJws/yRCDEK/hzcwVihhqk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manpreet121990/manpreetcode/blob/main/lab%202%20mahd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbvR30o70D3V",
        "outputId": "6ad0a534-3cb5-4911-c498-9f9556db5c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load CIFAR-10 (preprocessing omitted for brevity, assume X_train, y_train, X_test, y_test are ready)\n",
        "# Remember to resize images to 224x224 and one-hot encode labels\n",
        "(X_train_cifar, y_train_cifar), (X_test_cifar, y_test_cifar) = tf.keras.datasets.cifar10.load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16 # or VGG19\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Needed for scenario 3 for augmentation\n",
        "import numpy as np\n",
        "\n",
        "# --- GPU Check (CRITICAL FOR SPEED) ---\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "if tf.test.is_built_with_cuda():\n",
        "    print(\"TensorFlow is built with CUDA and should use GPU if available.\")\n",
        "else:\n",
        "    print(\"TensorFlow is NOT built with CUDA. Training will be slow on CPU. Please enable GPU runtime.\")\n",
        "# --- End GPU Check ---\n",
        "\n",
        "# 1. Load CIFAR-10 Dataset\n",
        "(X_train_cifar, y_train_cifar), (X_test_cifar, y_test_cifar) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Ensure X_train_cifar and X_test_cifar are float32 for consistency and normalization\n",
        "X_train_cifar = X_train_cifar.astype(np.float32)\n",
        "X_test_cifar = X_test_cifar.astype(np.float32)\n",
        "\n",
        "# One-hot encode labels\n",
        "num_classes = 10\n",
        "y_train_one_hot = tf.keras.utils.to_categorical(y_train_cifar, num_classes)\n",
        "y_test_one_hot = tf.keras.utils.to_categorical(y_test_cifar, num_classes)\n",
        "\n",
        "# --- Define Image Preprocessing and Batching ---\n",
        "# IMPORTANT CHANGE HERE: Experiment with these sizes!\n",
        "# Smaller values like (96, 96) or (64, 64) will be significantly faster.\n",
        "TARGET_IMAGE_SIZE = (96, 96) # <<<-- CHANGE THIS TO (96, 96) or (64, 64) for speed up\n",
        "BATCH_SIZE = 32 # Define your batch size\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "    # Resize image\n",
        "    image = tf.image.resize(image, TARGET_IMAGE_SIZE)\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Create train dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_cifar, y_train_one_hot))\n",
        "train_dataset = train_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=10000) # Shuffle the dataset\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE) # Prefetch for performance\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_cifar, y_test_one_hot))\n",
        "test_dataset = test_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(f\"\\n--- Data preparation complete. Images will be resized to {TARGET_IMAGE_SIZE}. ---\")\n",
        "print(f\"Train Dataset batches: {tf.data.experimental.cardinality(train_dataset).numpy()}\")\n",
        "print(f\"Test Dataset batches: {tf.data.experimental.cardinality(test_dataset).numpy()}\")\n",
        "\n",
        "\n",
        "# --- Scenario 1: Train model based on not updating the weights of pretrain model (Freeze all layers) ---\n",
        "print(\"\\n--- Starting Scenario 1: Training with Frozen VGG layers ---\")\n",
        "\n",
        "# IMPORTANT CHANGE HERE: Match input_shape to TARGET_IMAGE_SIZE\n",
        "base_model_frozen = VGG16(weights='imagenet', include_top=False, input_shape=(TARGET_IMAGE_SIZE[0], TARGET_IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the convolutional layers\n",
        "for layer in base_model_frozen.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new classification layers on top\n",
        "x_frozen = base_model_frozen.output\n",
        "x_frozen = Flatten()(x_frozen)\n",
        "x_frozen = Dense(256, activation='relu')(x_frozen)\n",
        "predictions_frozen = Dense(num_classes, activation='softmax')(x_frozen)\n",
        "\n",
        "model_frozen = Model(inputs=base_model_frozen.input, outputs=predictions_frozen)\n",
        "\n",
        "# Compile the model\n",
        "model_frozen.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the tf.data.Dataset\n",
        "history_frozen = model_frozen.fit(train_dataset,\n",
        "                                  epochs=5, # You can start with fewer epochs (e.g., 5) for quick testing\n",
        "                                  validation_data=test_dataset)\n",
        "\n",
        "print(\"\\n--- Scenario 1: Training with frozen VGG layers complete ---\")\n",
        "print(f\"Scenario 1 - Final Validation Accuracy: {history_frozen.history['val_accuracy'][-1]:.4f}\")\n",
        "\n",
        "\n",
        "# --- Scenario 2: Train based on updating partial layers of pretrain model (Partial Fine-tuning) ---\n",
        "print(\"\\n--- Starting Scenario 2: Training with Partially Unfrozen VGG layers (Fine-tuning) ---\")\n",
        "\n",
        "# Re-load base_model to ensure all layers are initially trainable, then selectively freeze\n",
        "# IMPORTANT CHANGE HERE: Match input_shape to TARGET_IMAGE_SIZE\n",
        "base_model_partial = VGG16(weights='imagenet', include_top=False, input_shape=(TARGET_IMAGE_SIZE[0], TARGET_IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Unfreeze layers from 'block5_conv1' onwards.\n",
        "set_trainable = False\n",
        "for layer in base_model_partial.layers:\n",
        "    if layer.name == 'block5_conv1': # Unfreeze from this layer onwards\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "# Add new classification layers on top (same as Scenario 1)\n",
        "x_partial = base_model_partial.output\n",
        "x_partial = Flatten()(x_partial)\n",
        "x_partial = Dense(256, activation='relu')(x_partial)\n",
        "predictions_partial = Dense(num_classes, activation='softmax')(x_partial)\n",
        "\n",
        "model_partial = Model(inputs=base_model_partial.input, outputs=predictions_partial)\n",
        "\n",
        "# It's recommended to use a smaller learning rate for fine-tuning\n",
        "model_partial.compile(optimizer=Adam(learning_rate=0.00001), # Smaller learning rate for fine-tuning\n",
        "                      loss='categorical_crossentropy',\n",
        "\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the tf.data.Dataset\n",
        "history_partial = model_partial.fit(train_dataset,\n",
        "                                    epochs=8, # Often requires more epochs than frozen layers\n",
        "                                    validation_data=test_dataset)\n",
        "\n",
        "print(\"\\n--- Scenario 2: Training with partially unfrozen VGG layers complete ---\")\n",
        "print(f\"Scenario 2 - Final Validation Accuracy: {history_partial.history['val_accuracy'][-1]:.4f}\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "p79MeCds1AYa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "5cea33a9-a671-45b3-aad7-2582b37caf2b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "TensorFlow is built with CUDA and should use GPU if available.\n",
            "\n",
            "--- Data preparation complete. Images will be resized to (96, 96). ---\n",
            "Train Dataset batches: 1563\n",
            "Test Dataset batches: 313\n",
            "\n",
            "--- Starting Scenario 1: Training with Frozen VGG layers ---\n",
            "Epoch 1/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 52ms/step - accuracy: 0.6161 - loss: 1.1157 - val_accuracy: 0.7355 - val_loss: 0.7657\n",
            "Epoch 2/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 56ms/step - accuracy: 0.7474 - loss: 0.7221 - val_accuracy: 0.7504 - val_loss: 0.7132\n",
            "Epoch 3/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 57ms/step - accuracy: 0.7796 - loss: 0.6330 - val_accuracy: 0.7449 - val_loss: 0.7269\n",
            "Epoch 4/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 56ms/step - accuracy: 0.8000 - loss: 0.5642 - val_accuracy: 0.7330 - val_loss: 0.7997\n",
            "Epoch 5/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 56ms/step - accuracy: 0.8215 - loss: 0.5090 - val_accuracy: 0.7668 - val_loss: 0.7186\n",
            "\n",
            "--- Scenario 1: Training with frozen VGG layers complete ---\n",
            "Scenario 1 - Final Validation Accuracy: 0.7668\n",
            "\n",
            "--- Starting Scenario 2: Training with Partially Unfrozen VGG layers (Fine-tuning) ---\n",
            "Epoch 1/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 76ms/step - accuracy: 0.5974 - loss: 1.1769 - val_accuracy: 0.7844 - val_loss: 0.6212\n",
            "Epoch 2/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 70ms/step - accuracy: 0.8175 - loss: 0.5330 - val_accuracy: 0.8149 - val_loss: 0.5385\n",
            "Epoch 3/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 74ms/step - accuracy: 0.8632 - loss: 0.4035 - val_accuracy: 0.8290 - val_loss: 0.4888\n",
            "Epoch 4/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 74ms/step - accuracy: 0.8955 - loss: 0.3159 - val_accuracy: 0.8353 - val_loss: 0.4781\n",
            "Epoch 5/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 70ms/step - accuracy: 0.9183 - loss: 0.2505 - val_accuracy: 0.8508 - val_loss: 0.4497\n",
            "Epoch 6/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 74ms/step - accuracy: 0.9386 - loss: 0.1974 - val_accuracy: 0.8458 - val_loss: 0.4657\n",
            "Epoch 7/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 74ms/step - accuracy: 0.9529 - loss: 0.1560 - val_accuracy: 0.8494 - val_loss: 0.4739\n",
            "Epoch 8/8\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 74ms/step - accuracy: 0.9668 - loss: 0.1206 - val_accuracy: 0.8510 - val_loss: 0.4744\n",
            "\n",
            "--- Scenario 2: Training with partially unfrozen VGG layers complete ---\n",
            "Scenario 2 - Final Validation Accuracy: 0.8510\n",
            "\n",
            "--- Starting Scenario 3: Fine-tuning with Data Augmentation ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ImageDataGenerator.flow() got an unexpected keyword argument 'target_size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-968307678.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0mtest_datagen_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m train_generator_aug = train_datagen_aug.flow(\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0mX_train_cifar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ImageDataGenerator.flow() got an unexpected keyword argument 'target_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# No longer strictly need ImageDataGenerator if we use tf.data.Dataset for augmentation\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # For optional visualization\n",
        "\n",
        "# --- GPU Check (CRITICAL FOR SPEED) ---\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "if tf.test.is_built_with_cuda():\n",
        "    print(\"TensorFlow is built with CUDA and should use GPU if available.\")\n",
        "else:\n",
        "    print(\"TensorFlow is NOT built with CUDA. Training will be slow on CPU. Please enable GPU runtime.\")\n",
        "# --- End GPU Check ---\n",
        "\n",
        "# 1. Load CIFAR-10 Dataset\n",
        "(X_train_cifar, y_train_cifar), (X_test_cifar, y_test_cifar) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Ensure data types are float32 for image processing\n",
        "X_train_cifar = X_train_cifar.astype(np.float32)\n",
        "X_test_cifar = X_test_cifar.astype(np.float32)\n",
        "\n",
        "# One-hot encode labels\n",
        "num_classes = 10\n",
        "y_train_one_hot = tf.keras.utils.to_categorical(y_train_cifar, num_classes)\n",
        "y_test_one_hot = tf.keras.utils.to_categorical(y_test_cifar, num_classes)\n",
        "\n",
        "# --- Define Global Parameters ---\n",
        "TARGET_IMAGE_SIZE = (96, 96) # Experiment with (224, 224), (96, 96), or (64, 64)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- Preprocessing and Augmentation Functions for tf.data.Dataset ---\n",
        "\n",
        "def augment_image(image, label):\n",
        "    # Apply augmentations (TensorFlow ops are efficient)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "    # Add more augmentations as needed\n",
        "    # tf.image.random_rotation is not directly available, can be done with tf.keras.layers.RandomRotation\n",
        "    # or custom logic using tf.raw_ops.ImageProjectiveTransformV2\n",
        "\n",
        "    # Clip values to ensure they stay in [0, 1] after augmentations\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
        "    return image, label\n",
        "\n",
        "def preprocess_and_augment(image, label):\n",
        "    # Resize first\n",
        "    image = tf.image.resize(image, TARGET_IMAGE_SIZE)\n",
        "    # Normalize\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Apply augmentation ONLY to training data\n",
        "    # (The `map` function will be called on `train_dataset` only for augmentation)\n",
        "    return augment_image(image, label)\n",
        "\n",
        "def preprocess_only(image, label):\n",
        "    # Resize first\n",
        "    image = tf.image.resize(image, TARGET_IMAGE_SIZE)\n",
        "    # Normalize\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# --- Create tf.data.Dataset for Training (with augmentation) ---\n",
        "train_dataset_augmented = tf.data.Dataset.from_tensor_slices((X_train_cifar, y_train_one_hot))\n",
        "train_dataset_augmented = train_dataset_augmented.map(preprocess_and_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset_augmented = train_dataset_augmented.shuffle(buffer_size=10000)\n",
        "train_dataset_augmented = train_dataset_augmented.batch(BATCH_SIZE)\n",
        "train_dataset_augmented = train_dataset_augmented.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# --- Create tf.data.Dataset for Testing (no augmentation) ---\n",
        "test_dataset_preprocessed = tf.data.Dataset.from_tensor_slices((X_test_cifar, y_test_one_hot))\n",
        "test_dataset_preprocessed = test_dataset_preprocessed.map(preprocess_only, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset_preprocessed = test_dataset_preprocessed.batch(BATCH_SIZE)\n",
        "test_dataset_preprocessed = test_dataset_preprocessed.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(f\"\\n--- Data preparation complete. Images will be resized to {TARGET_IMAGE_SIZE}. ---\")\n",
        "print(f\"Train Dataset (augmented) batches: {tf.data.experimental.cardinality(train_dataset_augmented).numpy()}\")\n",
        "print(f\"Test Dataset batches: {tf.data.experimental.cardinality(test_dataset_preprocessed).numpy()}\")\n",
        "\n",
        "# --- Scenario 3: Apply some layers on the top of model + use data augmentation and train the model ---\n",
        "print(\"\\n--- Starting Scenario 3: Fine-tuning with Data Augmentation (tf.data.Dataset) ---\")\n",
        "\n",
        "# Load base model\n",
        "base_model_aug = VGG16(weights='imagenet', include_top=False, input_shape=(TARGET_IMAGE_SIZE[0], TARGET_IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Fine-tuning strategy: Unfreeze layers. Example: unfreeze from block5_conv1 onwards.\n",
        "set_trainable_aug = False\n",
        "for layer in base_model_aug.layers:\n",
        "    if layer.name == 'block5_conv1': # Unfreeze from this layer onwards\n",
        "        set_trainable_aug = True\n",
        "    if set_trainable_aug:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "# Add new classification layers on top\n",
        "x_aug = base_model_aug.output\n",
        "x_aug = Flatten()(x_aug)\n",
        "x_aug = Dense(256, activation='relu')(x_aug)\n",
        "predictions_aug = Dense(num_classes, activation='softmax')(x_aug)\n",
        "\n",
        "model_aug = Model(inputs=base_model_aug.input, outputs=predictions_aug)\n",
        "\n",
        "# Compile with a very small learning rate for fine-tuning\n",
        "model_aug.compile(optimizer=Adam(learning_rate=0.000005),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the tf.data.Dataset with augmentation\n",
        "history_aug = model_aug.fit(train_dataset_augmented, # Use the augmented dataset\n",
        "                            epochs=7\n",
        "                            , # More epochs are often needed with data augmentation\n",
        "                            validation_data=test_dataset_preprocessed) # Use the non-augmented test set\n",
        "\n",
        "print(\"\\n--- Scenario 3: Training with fine-tuning and data augmentation complete ---\")\n",
        "print(f\"Scenario 3 - Final Validation Accuracy: {history_aug.history['val_accuracy'][-1]:.4f}\")"
      ],
      "metadata": {
        "id": "E-hZul145Lax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a25a48a-40f6-411d-c372-a5c0098e9325"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "TensorFlow is built with CUDA and should use GPU if available.\n",
            "\n",
            "--- Data preparation complete. Images will be resized to (96, 96). ---\n",
            "Train Dataset (augmented) batches: 1563\n",
            "Test Dataset batches: 313\n",
            "\n",
            "--- Starting Scenario 3: Fine-tuning with Data Augmentation (tf.data.Dataset) ---\n",
            "Epoch 1/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 76ms/step - accuracy: 0.5057 - loss: 1.4261 - val_accuracy: 0.7525 - val_loss: 0.7248\n",
            "Epoch 2/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 70ms/step - accuracy: 0.7747 - loss: 0.6626 - val_accuracy: 0.8017 - val_loss: 0.5900\n",
            "Epoch 3/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 76ms/step - accuracy: 0.8065 - loss: 0.5580 - val_accuracy: 0.8073 - val_loss: 0.5551\n",
            "Epoch 4/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 75ms/step - accuracy: 0.8283 - loss: 0.4867 - val_accuracy: 0.8210 - val_loss: 0.5119\n",
            "Epoch 5/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 75ms/step - accuracy: 0.8481 - loss: 0.4400 - val_accuracy: 0.8295 - val_loss: 0.4915\n",
            "Epoch 6/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 76ms/step - accuracy: 0.8594 - loss: 0.4064 - val_accuracy: 0.8409 - val_loss: 0.4606\n",
            "Epoch 7/7\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 71ms/step - accuracy: 0.8708 - loss: 0.3758 - val_accuracy: 0.8487 - val_loss: 0.4429\n",
            "\n",
            "--- Scenario 3: Training with fine-tuning and data augmentation complete ---\n",
            "Scenario 3 - Final Validation Accuracy: 0.8487\n"
          ]
        }
      ]
    }
  ]
}